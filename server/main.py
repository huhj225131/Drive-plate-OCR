from fastapi import FastAPI
from contextlib import asynccontextmanager
from pydantic import BaseModel
import base64
import cv2
import numpy as np

# Import class nháº­n diá»‡n cá»§a báº¡n
from model_yolo_paddle import ImgToPlate

# Biáº¿n toÃ n cá»¥c Ä‘á»ƒ chá»©a model
ml_models = {}

# --- 1. LIFESPAN: Cháº¡y khi server báº­t ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    print("ğŸ”„ Äang load cÃ¡c Model AI... Vui lÃ²ng chá»...")
    
    # Khá»Ÿi táº¡o model á»Ÿ Ä‘Ã¢y. NÃ³ sáº½ chá»‰ cháº¡y 1 láº§n duy nháº¥t.
    # 'ocr_version'='PP-OCRv4' thÆ°á»ng máº·c Ä‘á»‹nh lÃ  mobile, nháº¹ hÆ¡n server
    ml_models["plate_detector"] = ImgToPlate() 
    
    # Máº¹o: Cháº¡y thá»­ 1 láº§n dummy (Warm-up) Ä‘á»ƒ cÃ¡c thÆ° viá»‡n load háº¿t vÃ o cache
    dummy_img = np.zeros((640, 640, 3), dtype=np.uint8)
    print("ğŸ”¥ Warming up model...")
    try:
        ml_models["plate_detector"](dummy_img) 
    except:
        pass # Bá» qua lá»—i náº¿u cÃ³, má»¥c Ä‘Ã­ch chá»‰ Ä‘á»ƒ load thÆ° viá»‡n
        
    print("âœ… Model Ä‘Ã£ sáºµn sÃ ng!")
    yield
    
    # Code cháº¡y khi server táº¯t (dá»n dáº¹p bá»™ nhá»› náº¿u cáº§n)
    ml_models.clear()
    print("ğŸ›‘ Server shutting down")

class ImagePayload(BaseModel):
    image: str  # Base64 string

# Gáº¯n lifespan vÃ o app
app = FastAPI(lifespan=lifespan)

@app.get("/")
async def root():
    return {"message": "Server is running"}

@app.post("/get_plate")
async def img_plate(payload: ImagePayload):
    # 1. Decode Base64
    try:
        img_bytes = base64.b64decode(payload.image)
        nparr = np.frombuffer(img_bytes, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    except Exception as e:
        return {"error": "Invalid image data"}

    # 2. Gá»i model Ä‘Ã£ load sáºµn tá»« lifespan
    # LÆ°u Ã½: Cáº§n sá»­a class ImgToPlate Ä‘á»ƒ nháº­n numpy array (xem BÆ°á»›c 2 dÆ°á»›i)
    detector = ml_models["plate_detector"]
    result = detector(img) 
    
    return {"message": result}